# LISTA DE LABORATÓRIOS
*Lista de Laboratórios disponiveis pela Google Cloud no* [*Cloud Skills Boost*](https://www.cloudskillsboost.google/). 

<br>

## :small_blue_diamond: Dataflow: Qwik Start – Python
* Neste laboratório, você configurará um ambiente de desenvolvimento em Python, instalará o SDK do Cloud Dataflow para Python e executará um pipeline de exemplo usando o Console do Google Cloud Platform.
[ACESSAR LABORATÓRIO](https://www.cloudskillsboost.google/focuses/1100?locale=en&parent=catalog)
<br>

## :small_blue_diamond: Dataflow: Qwik Start - Templates
* Neste laboratório, você aprenderá a criar um pipeline de streaming usando um dos modelos do Cloud Dataflow do Google. Mais especificamente, você usará o modelo Cloud Pub/Sub para BigQuery, que lê mensagens escritas em JSON de um tópico Pub/Sub e as envia para uma tabela do BigQuery.
[ACESSAR LABORATÓRIO](https://www.cloudskillsboost.google/focuses/1101?locale=en&parent=catalog)

> MATERIAL DE APOIO:
> [*Documentação de como usar Modelos/Templates*](https://cloud.google.com/dataflow/docs/concepts/dataflow-templates?hl=pt-br)
<br>

## :small_blue_diamond: Processing Data with Google Cloud Dataflow
* Neste laboratório, você irá simular um conjunto de dados do mundo real, em tempo real, de um conjunto de dados histórico. Você usará o Python e o Dataflow para processar um conjunto de dados simulados de um conjunto de arquivos de texto e depois usará o BigQuery para armazenar e analisar os dados resultantes.
[ACESSAR LABORATÓRIO](https://www.cloudskillsboost.google/focuses/1159?locale=en&parent=catalog)
<br>

## :small_blue_diamond: Data Warehousing for Partners: Process Data with Dataflow
* Este curso continua a explorar a implementação de pipelines de carga e transformação de dados para um BigQuery Data Warehouse usando o Dataflow.

:warning: PARA ACESSAR ESTE CURSO/LABORATÓRIO é necessário procurar pelo seu nome direto no [Catalog](https://partner.cloudskillsboost.google/catalog).

<br>

## :small_blue_diamond: ETL Processing on Google Cloud Using Dataflow and BigQuery
* Neste laboratório, você cria vários pipelines de dados que ingerem dados de um conjunto de dados disponível publicamente no BigQuery, criando seu próprio Data Pipeline, incluindo as considerações de design, bem como detalhes de implementação, para garantir que seu protótipo atenda aos requisitos. [ACESSAR LABORATÓRIO](https://www.cloudskillsboost.google/focuses/3460?locale=en&parent=catalog)
> SERVIÇOS DO GOOGLE CLOUD USADOS NESSE LABORATÓRIO
> * Cloud Storage;
> * Dataflow;
> * BigQuery.



<br>

## :small_blue_diamond: Dataflow Academy (Python) - Lab 2 - Branching Pipelines and Custom Dataflow Flex Templates
* Neste laboratório, você irá:
1. Implementar um pipeline que tenha ramificações;
2. Filtrar os dados antes de gravar;
3. Adicionar parâmetros de linha de comando personalizados a um pipeline;
4. Converter um pipeline personalizado em um modelo flexível do Dataflow personalizado;
5. Executar um modelo flexível do Dataflow.

:warning: PARA ACESSAR ESTE LABORATÓRIO é necessário procurar pelo seu nome direto no [Catalog](https://partner.cloudskillsboost.google/catalog).

> MATERIAL DE APOIO:
> [*Documentação de como usar modelo Fléxivel*](https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates?hl=pt-br)
